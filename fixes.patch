# Erstellt von pylint_patcher.py am 2025-03-01 18:16:24

--- a/uploadready.py
+++ b/uploadready.py
@@ -1,7 +1,4 @@
-"""
-uploadready - Modulbeschreibung.
-"""
-
+"""
uploadready - Modulbeschreibung.
"""

 import os
 import json
 import subprocess
@@ -99,9 +96,7 @@
 ssh_key,
 use_pat=False):
     """" +
-        "" +
-            "" +
-            "Synchronisiert das lokale Repository mit GitHub über SSH oder PAT und führt einen Merge durch, wenn nötig."""
+        "" +
            "" +
            "Synchronisiert das lokale Repository mit GitHub über SSH oder PAT und führt einen Merge durch, wenn nötig."""
     try:
         # GitHub-URL vorbereiten
         if use_pat:
@@ -124,8 +119,7 @@
         # Falls der Fehler bei der Authentifizierung liegt, frage nach dem PAT
         if "fatal: Authentifizierung" in str(e):
             print("" +
-                "" +
-                    "Fehler bei der Authentifizierung. Bitte prüfe deinen SSH-Schlüssel oder Personal Access Token.")
+                "" +
                    "Fehler bei der Authentifizierung. Bitte prüfe deinen SSH-Schlüssel oder Personal Access Token.")
         else:
             print(f"Git Fehler: {str(e)}")
 

--- a/client/cleanup.py
+++ b/client/cleanup.py
@@ -6,9 +6,7 @@
 
 # Funktion zum Hinzufügen von Docstrings zu Modulen und Funktionen
 def add_docstrings(file_path):
-"""
-Beschreibung für Funktion add_docstrings.
-"""
+"""
Beschreibung für Funktion add_docstrings.
"""
     try:
         with open(file_path, 'r', encoding="utf-8") as file:
             lines = file.readlines()

--- a/client/backend/ai_model.py
+++ b/client/backend/ai_model.py
@@ -352,8 +352,7 @@
             model="gpt-4",
 
             messages=[
-                {"role": "system", "content": "" +
-                    "You are a log analysis expert. Provide clear, concise analysis of log files."},
+                {"role": "system", "content": "" +
                    "You are a log analysis expert. Provide clear, concise analysis of log files."},
                 {"role": "user", "content": prompt}
             ],
             max_tokens=1024,

--- a/client/backend/hugging.py
+++ b/client/backend/hugging.py
@@ -37,9 +37,7 @@
         print(f"Fehler beim Laden des Modells {model_name}: {e}")
 
 def main():
-"""
-Beschreibung für Funktion main.
-"""
+"""
Beschreibung für Funktion main.
"""
     print("Willkommen bei der Hugging Face App!")
     print("1. Suche Modelle nach Kategorie")
     print("2. Suche Modelle nach Text")

--- a/client/frontend/twitchbot.py
+++ b/client/frontend/twitchbot.py
@@ -6,9 +6,7 @@
 import os
 
 class Bot(commands.Bot):
-"""
-Beschreibung für Klasse Bot.
-"""
+"""
Beschreibung für Klasse Bot.
"""
     def __init__(self):
         token = os.getenv("TWITCH_BOT_TOKEN")
         channels = os.getenv("derleiti.de", "#default_channel").split(",")

--- a/client/frontend/config.py
+++ b/client/frontend/config.py
@@ -13,12 +13,8 @@
 }
 
 def get(key):
-"""
-Beschreibung für Funktion get.
-"""
-"""
-Beschreibung für Funktion get.
-"""
+"""
Beschreibung für Funktion get.
"""
+"""
Beschreibung für Funktion get.
"""
     return CONFIG.get(key)
 
 def set_config(key, value):

--- a/server/backend/app.py
+++ b/server/backend/app.py
@@ -68,8 +68,7 @@
 
         logger.info(f"Received log for analysis using model: {model_name}")
         logger.debug(f"" +
-            "" +
-                "Log content (truncated): {log_text[:100]}..." if len(log_text) > 100 else f"Log content: {log_text}")
+            "" +
                "Log content (truncated): {log_text[:100]}..." if len(log_text) > 100 else f"Log content: {log_text}")
 
         # Process and analyze the log
         response = analyze_log(log_text, model_name, instruction)

--- a/server/backend/ai_model.py
+++ b/server/backend/ai_model.py
@@ -355,8 +355,7 @@
             model="gpt-4",
 
             messages=[
-                {"role": "system", "content": "" +
-                    "You are a log analysis expert. Provide clear, concise analysis of log files."},
+                {"role": "system", "content": "" +
                    "You are a log analysis expert. Provide clear, concise analysis of log files."},
                 {"role": "user", "content": prompt}
             ],
             max_tokens=1024,

