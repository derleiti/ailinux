************* Module client.start
client/start.js:1:1: E0001: Parsing failed: 'invalid syntax (client.start, line 1)' (syntax-error)
************* Module client.websocket-client
client/websocket-client.py:317:5: E0001: Parsing failed: 'expected an indented block after function definition on line 316 (client.websocket-client, line 317)' (syntax-error)
************* Module client.cleanup
client/cleanup.py:9:1: E0001: Parsing failed: 'expected an indented block after function definition on line 8 (client.cleanup, line 9)' (syntax-error)
************* Module client.backend.huggingface
client/backend/huggingface.py:124:52: E0001: Parsing failed: 'unterminated string literal (detected at line 124) (client.backend.huggingface, line 124)' (syntax-error)
************* Module client.backend.hugging
client/backend/hugging.py:40:1: E0001: Parsing failed: 'expected an indented block after function definition on line 39 (client.backend.hugging, line 40)' (syntax-error)
************* Module client.frontend.twitchbot
client/frontend/twitchbot.py:9:1: E0001: Parsing failed: 'expected an indented block after class definition on line 8 (client.frontend.twitchbot, line 9)' (syntax-error)
************* Module client.frontend.settings
client/frontend/settings.html:8:53: E0001: Parsing failed: 'invalid decimal literal (client.frontend.settings, line 8)' (syntax-error)
************* Module client.frontend.logmanager
client/frontend/logmanager.js:1:1: E0001: Parsing failed: 'invalid syntax (client.frontend.logmanager, line 1)' (syntax-error)
************* Module client.frontend.config
client/frontend/config.py:16:1: E0001: Parsing failed: 'expected an indented block after function definition on line 15 (client.frontend.config, line 16)' (syntax-error)
************* Module client.frontend.preload
client/frontend/preload.js:19:43: E0001: Parsing failed: 'unterminated string literal (detected at line 19) (client.frontend.preload, line 19)' (syntax-error)
************* Module client.frontend.importexport
client/frontend/importexport.js:4:49: E0001: Parsing failed: 'unterminated string literal (detected at line 4) (client.frontend.importexport, line 4)' (syntax-error)
************* Module client.frontend.index
client/frontend/index.html:29:44: E0001: Parsing failed: 'invalid decimal literal (client.frontend.index, line 29)' (syntax-error)
************* Module client.frontend.gemini-api-setup
client/frontend/gemini-api-setup.js:1:7: E0001: Parsing failed: 'invalid syntax (client.frontend.gemini-api-setup, line 1)' (syntax-error)
************* Module client.frontend.main
client/frontend/main.js:1:1: E0001: Parsing failed: 'invalid syntax (client.frontend.main, line 1)' (syntax-error)
client/frontend/config.js:16:1: E0001: Parsing failed: 'expected an indented block after function definition on line 15 (client.frontend.config, line 16)' (syntax-error)
************* Module client.frontend.log
client/frontend/log.html:1:1: E0001: Parsing failed: 'invalid syntax (client.frontend.log, line 1)' (syntax-error)
************* Module client.frontend.aiineraction
client/frontend/aiineraction.html:9:16: E0001: Parsing failed: 'invalid decimal literal (client.frontend.aiineraction, line 9)' (syntax-error)
************* Module client.frontend.llama
client/frontend/llama.html:9:16: E0001: Parsing failed: 'invalid decimal literal (client.frontend.llama, line 9)' (syntax-error)
************* Module patch.ailinux-alpha-patch-v0.4
patch/ailinux-alpha-patch-v0.4.py:122:29: E0001: Parsing failed: 'unterminated f-string literal (detected at line 122) (patch.ailinux-alpha-patch-v0.4, line 122)' (syntax-error)
************* Module patch.ailinux-alpha-patch-v0.2
patch/ailinux-alpha-patch-v0.2.py:37:34: E0001: Parsing failed: 'invalid syntax (patch.ailinux-alpha-patch-v0.2, line 37)' (syntax-error)
************* Module patch.ailinux-alpha-patch-v0.5
patch/ailinux-alpha-patch-v0.5.py:142:29: E0001: Parsing failed: 'unterminated f-string literal (detected at line 142) (patch.ailinux-alpha-patch-v0.5, line 142)' (syntax-error)
************* Module patch.ailinux-alpha-patch-v0.1
patch/ailinux-alpha-patch-v0.1.py:213:16: E0001: Parsing failed: 'invalid syntax (patch.ailinux-alpha-patch-v0.1, line 213)' (syntax-error)
************* Module server.backend.app
server/backend/app.py:298:41: E0001: Parsing failed: 'unterminated string literal (detected at line 298) (server.backend.app, line 298)' (syntax-error)
************* Module server.backend.data_server
server/backend/data_server.py:254:13: E0001: Parsing failed: 'expected 'except' or 'finally' block (server.backend.data_server, line 254)' (syntax-error)
************* Module uploadready
uploadready.py:101:0: C0301: Line too long (116/100) (line-too-long)
uploadready.py:123:0: C0301: Line too long (115/100) (line-too-long)
uploadready.py:18:17: W0612: Unused variable 'dirnames' (unused-variable)
uploadready.py:61:16: R1732: Consider using 'with' for resource-allocating operations (consider-using-with)
uploadready.py:41:22: W0612: Unused variable 'file_info' (unused-variable)
uploadready.py:45:17: W0612: Unused variable 'dirnames' (unused-variable)
uploadready.py:68:8: W0612: Unused variable 'dirpath' (unused-variable)
uploadready.py:94:17: W1510: 'subprocess.run' used without explicitly defining the value for 'check'. (subprocess-run-check)
************* Module fix_duplicate_code
fix_duplicate_code.py:23:0: C0303: Trailing whitespace (trailing-whitespace)
fix_duplicate_code.py:29:0: C0303: Trailing whitespace (trailing-whitespace)
fix_duplicate_code.py:37:0: C0303: Trailing whitespace (trailing-whitespace)
fix_duplicate_code.py:42:0: C0303: Trailing whitespace (trailing-whitespace)
fix_duplicate_code.py:46:0: C0303: Trailing whitespace (trailing-whitespace)
fix_duplicate_code.py:51:0: C0303: Trailing whitespace (trailing-whitespace)
fix_duplicate_code.py:57:0: C0303: Trailing whitespace (trailing-whitespace)
fix_duplicate_code.py:64:0: C0303: Trailing whitespace (trailing-whitespace)
fix_duplicate_code.py:67:0: C0303: Trailing whitespace (trailing-whitespace)
fix_duplicate_code.py:71:0: C0303: Trailing whitespace (trailing-whitespace)
fix_duplicate_code.py:79:0: C0303: Trailing whitespace (trailing-whitespace)
fix_duplicate_code.py:84:0: C0303: Trailing whitespace (trailing-whitespace)
fix_duplicate_code.py:88:0: C0303: Trailing whitespace (trailing-whitespace)
fix_duplicate_code.py:100:0: C0303: Trailing whitespace (trailing-whitespace)
fix_duplicate_code.py:108:0: C0303: Trailing whitespace (trailing-whitespace)
fix_duplicate_code.py:117:0: C0303: Trailing whitespace (trailing-whitespace)
fix_duplicate_code.py:122:0: C0303: Trailing whitespace (trailing-whitespace)
fix_duplicate_code.py:125:0: C0303: Trailing whitespace (trailing-whitespace)
fix_duplicate_code.py:131:0: C0303: Trailing whitespace (trailing-whitespace)
fix_duplicate_code.py:133:0: C0303: Trailing whitespace (trailing-whitespace)
fix_duplicate_code.py:136:0: C0303: Trailing whitespace (trailing-whitespace)
fix_duplicate_code.py:143:0: C0303: Trailing whitespace (trailing-whitespace)
fix_duplicate_code.py:147:0: C0303: Trailing whitespace (trailing-whitespace)
fix_duplicate_code.py:152:0: C0303: Trailing whitespace (trailing-whitespace)
fix_duplicate_code.py:155:0: C0301: Line too long (106/100) (line-too-long)
fix_duplicate_code.py:156:0: C0303: Trailing whitespace (trailing-whitespace)
fix_duplicate_code.py:159:0: C0303: Trailing whitespace (trailing-whitespace)
fix_duplicate_code.py:162:0: C0303: Trailing whitespace (trailing-whitespace)
fix_duplicate_code.py:166:0: C0303: Trailing whitespace (trailing-whitespace)
fix_duplicate_code.py:172:0: C0303: Trailing whitespace (trailing-whitespace)
fix_duplicate_code.py:181:0: C0303: Trailing whitespace (trailing-whitespace)
fix_duplicate_code.py:186:0: C0303: Trailing whitespace (trailing-whitespace)
fix_duplicate_code.py:189:0: C0303: Trailing whitespace (trailing-whitespace)
fix_duplicate_code.py:194:0: C0303: Trailing whitespace (trailing-whitespace)
fix_duplicate_code.py:196:0: C0301: Line too long (102/100) (line-too-long)
fix_duplicate_code.py:197:0: C0303: Trailing whitespace (trailing-whitespace)
fix_duplicate_code.py:201:0: C0303: Trailing whitespace (trailing-whitespace)
fix_duplicate_code.py:205:0: C0301: Line too long (103/100) (line-too-long)
fix_duplicate_code.py:209:0: C0303: Trailing whitespace (trailing-whitespace)
fix_duplicate_code.py:214:0: C0303: Trailing whitespace (trailing-whitespace)
fix_duplicate_code.py:217:0: C0303: Trailing whitespace (trailing-whitespace)
fix_duplicate_code.py:225:0: C0303: Trailing whitespace (trailing-whitespace)
fix_duplicate_code.py:229:0: C0303: Trailing whitespace (trailing-whitespace)
fix_duplicate_code.py:232:0: C0303: Trailing whitespace (trailing-whitespace)
fix_duplicate_code.py:235:0: C0303: Trailing whitespace (trailing-whitespace)
fix_duplicate_code.py:240:0: C0303: Trailing whitespace (trailing-whitespace)
fix_duplicate_code.py:242:0: C0304: Final newline missing (missing-final-newline)
fix_duplicate_code.py:21:0: R0903: Too few public methods (1/2) (too-few-public-methods)
fix_duplicate_code.py:58:4: R0914: Too many local variables (21/15) (too-many-locals)
fix_duplicate_code.py:132:8: W1203: Use lazy % formatting in logging functions (logging-fstring-interpolation)
fix_duplicate_code.py:148:12: W1201: Use lazy % formatting in logging functions (logging-not-lazy)
fix_duplicate_code.py:149:12: W1203: Use lazy % formatting in logging functions (logging-fstring-interpolation)
fix_duplicate_code.py:151:16: W1203: Use lazy % formatting in logging functions (logging-fstring-interpolation)
fix_duplicate_code.py:163:12: W1203: Use lazy % formatting in logging functions (logging-fstring-interpolation)
fix_duplicate_code.py:163:29: W1309: Using an f-string that does not have any interpolated variables (f-string-without-interpolation)
fix_duplicate_code.py:164:12: W1203: Use lazy % formatting in logging functions (logging-fstring-interpolation)
fix_duplicate_code.py:165:12: W1203: Use lazy % formatting in logging functions (logging-fstring-interpolation)
fix_duplicate_code.py:165:29: W1309: Using an f-string that does not have any interpolated variables (f-string-without-interpolation)
fix_duplicate_code.py:169:16: W1203: Use lazy % formatting in logging functions (logging-fstring-interpolation)
fix_duplicate_code.py:171:20: W1203: Use lazy % formatting in logging functions (logging-fstring-interpolation)
fix_duplicate_code.py:180:16: W1203: Use lazy % formatting in logging functions (logging-fstring-interpolation)
fix_duplicate_code.py:242:16: W0104: Statement seems to have no effect (pointless-statement)
fix_duplicate_code.py:226:4: R1710: Either all return statements in a function should return an expression, or none of them should. (inconsistent-return-statements)
fix_duplicate_code.py:239:12: W0612: Unused variable 'words' (unused-variable)
fix_duplicate_code.py:14:0: W0611: Unused import sys (unused-import)
fix_duplicate_code.py:15:0: W0611: Unused import argparse (unused-import)
fix_duplicate_code.py:16:0: W0611: Unused Set imported from typing (unused-import)
fix_duplicate_code.py:18:0: W0611: Unused import difflib (unused-import)
************* Module client.alphaos
client/alphaos.py:55:11: W0718: Catching too general exception Exception (broad-exception-caught)
************* Module client.bigfiles
client/bigfiles.py:8:18: E0602: Undefined variable 'directory' (undefined-variable)
client/bigfiles.py:11:37: E0602: Undefined variable 'directory' (undefined-variable)
************* Module client.adjust_hierarchy_with_debugger
client/adjust_hierarchy_with_debugger.py:12:32: W0621: Redefining name 'base_dir' from outer scope (line 68) (redefined-outer-name)
client/adjust_hierarchy_with_debugger.py:68:4: C0103: Constant name "base_dir" doesn't conform to UPPER_CASE naming style (invalid-name)
************* Module client.analyze
client/analyze.py:5:0: C0103: Constant name "root_dir" doesn't conform to UPPER_CASE naming style (invalid-name)
client/analyze.py:14:0: C0103: Constant name "log_file_path" doesn't conform to UPPER_CASE naming style (invalid-name)
************* Module client.file-sync-client
client/file-sync-client.py:484:0: C0301: Line too long (104/100) (line-too-long)
client/file-sync-client.py:486:0: C0301: Line too long (121/100) (line-too-long)
client/file-sync-client.py:1:0: C0103: Module name "file-sync-client" doesn't conform to snake_case naming style (invalid-name)
client/file-sync-client.py:13:0: E0401: Unable to import 'paramiko' (import-error)
client/file-sync-client.py:33:18: W1508: os.getenv default type is builtins.int. Expected str or None. (invalid-envvar-default)
client/file-sync-client.py:43:20: W1508: os.getenv default type is builtins.int. Expected str or None. (invalid-envvar-default)
client/file-sync-client.py:46:20: W1508: os.getenv default type is builtins.int. Expected str or None. (invalid-envvar-default)
client/file-sync-client.py:72:19: W0718: Catching too general exception Exception (broad-exception-caught)
client/file-sync-client.py:72:12: W0612: Unused variable 'e' (unused-variable)
client/file-sync-client.py:87:15: W0718: Catching too general exception Exception (broad-exception-caught)
client/file-sync-client.py:87:8: W0612: Unused variable 'e' (unused-variable)
client/file-sync-client.py:103:15: W0718: Catching too general exception Exception (broad-exception-caught)
client/file-sync-client.py:103:8: W0612: Unused variable 'e' (unused-variable)
client/file-sync-client.py:152:15: W0718: Catching too general exception Exception (broad-exception-caught)
client/file-sync-client.py:123:16: W1201: Use lazy % formatting in logging functions (logging-not-lazy)
client/file-sync-client.py:123:28: W1309: Using an f-string that does not have any interpolated variables (f-string-without-interpolation)
client/file-sync-client.py:140:16: W0612: Unused variable 'stdin' (unused-variable)
client/file-sync-client.py:143:20: W0612: Unused variable 'error' (unused-variable)
client/file-sync-client.py:152:8: W0612: Unused variable 'e' (unused-variable)
client/file-sync-client.py:214:15: W0718: Catching too general exception Exception (broad-exception-caught)
client/file-sync-client.py:214:8: W0612: Unused variable 'e' (unused-variable)
client/file-sync-client.py:248:15: W0718: Catching too general exception Exception (broad-exception-caught)
client/file-sync-client.py:238:19: E0606: Possibly using variable 'stat' before assignment (possibly-used-before-assignment)
client/file-sync-client.py:248:8: W0612: Unused variable 'e' (unused-variable)
client/file-sync-client.py:274:15: W0718: Catching too general exception Exception (broad-exception-caught)
client/file-sync-client.py:266:16: W0612: Unused variable 'stdin' (unused-variable)
client/file-sync-client.py:269:20: W0612: Unused variable 'error' (unused-variable)
client/file-sync-client.py:274:8: W0612: Unused variable 'e' (unused-variable)
client/file-sync-client.py:309:15: W0718: Catching too general exception Exception (broad-exception-caught)
client/file-sync-client.py:309:8: W0612: Unused variable 'e' (unused-variable)
client/file-sync-client.py:338:15: W0718: Catching too general exception Exception (broad-exception-caught)
client/file-sync-client.py:338:8: W0612: Unused variable 'e' (unused-variable)
client/file-sync-client.py:356:15: W0718: Catching too general exception Exception (broad-exception-caught)
client/file-sync-client.py:356:8: W0612: Unused variable 'e' (unused-variable)
client/file-sync-client.py:375:15: W0718: Catching too general exception Exception (broad-exception-caught)
client/file-sync-client.py:375:8: W0612: Unused variable 'e' (unused-variable)
client/file-sync-client.py:490:15: W0718: Catching too general exception Exception (broad-exception-caught)
client/file-sync-client.py:385:8: R1702: Too many nested blocks (6/5) (too-many-nested-blocks)
client/file-sync-client.py:430:23: R1714: Consider merging these comparisons with 'in' by using 'SYNC_MODE in ('two-way', 'download')'. Use a set instead if elements are hashable. (consider-using-in)
client/file-sync-client.py:450:15: R1714: Consider merging these comparisons with 'in' by using 'SYNC_MODE in ('upload', 'two-way')'. Use a set instead if elements are hashable. (consider-using-in)
client/file-sync-client.py:455:15: R1714: Consider merging these comparisons with 'in' by using 'SYNC_MODE in ('download', 'two-way')'. Use a set instead if elements are hashable. (consider-using-in)
client/file-sync-client.py:465:15: R1714: Consider merging these comparisons with 'in' by using 'SYNC_MODE in ('upload', 'two-way')'. Use a set instead if elements are hashable. (consider-using-in)
client/file-sync-client.py:476:15: R1714: Consider merging these comparisons with 'in' by using 'SYNC_MODE in ('upload', 'two-way')'. Use a set instead if elements are hashable. (consider-using-in)
client/file-sync-client.py:480:23: W0718: Catching too general exception Exception (broad-exception-caught)
client/file-sync-client.py:1:0: F0002: client/file-sync-client.py: Fatal error while checking 'client/file-sync-client.py'. Please open an issue in our bug tracker so we address this. There is a pre-filled template that you can use in '/home/zombie/.cache/pylint/pylint-crash-2025-03-01-18-36-02.txt'. (astroid-error)
************* Module client.backend.app
client/backend/app.py:6:0: C0413: Import "import logging" should be placed at the top of the module (wrong-import-position)
client/backend/app.py:7:0: C0413: Import "import os" should be placed at the top of the module (wrong-import-position)
client/backend/app.py:8:0: C0413: Import "import sys" should be placed at the top of the module (wrong-import-position)
client/backend/app.py:9:0: C0413: Import "import traceback" should be placed at the top of the module (wrong-import-position)
client/backend/app.py:10:0: C0413: Import "from datetime import datetime" should be placed at the top of the module (wrong-import-position)
client/backend/app.py:11:0: C0413: Import "from flask import Flask, jsonify, request, send_from_directory" should be placed at the top of the module (wrong-import-position)
client/backend/app.py:12:0: C0413: Import "from flask_cors import CORS" should be placed at the top of the module (wrong-import-position)
client/backend/app.py:13:0: C0413: Import "from dotenv import load_dotenv" should be placed at the top of the module (wrong-import-position)
client/backend/app.py:14:0: C0413: Import "import psutil" should be placed at the top of the module (wrong-import-position)
client/backend/app.py:15:0: C0413: Import "from ai_model import analyze_log, get_available_models" should be placed at the top of the module (wrong-import-position)
client/backend/app.py:26:11: W1508: os.getenv default type is builtins.int. Expected str or None. (invalid-envvar-default)
client/backend/app.py:92:11: W0718: Catching too general exception Exception (broad-exception-caught)
client/backend/app.py:76:8: W1201: Use lazy % formatting in logging functions (logging-not-lazy)
client/backend/app.py:76:21: W1309: Using an f-string that does not have any interpolated variables (f-string-without-interpolation)
client/backend/app.py:94:8: W0612: Unused variable 'stack_trace' (unused-variable)
client/backend/app.py:116:11: W0718: Catching too general exception Exception (broad-exception-caught)
client/backend/app.py:131:11: W0718: Catching too general exception Exception (broad-exception-caught)
client/backend/app.py:153:11: W0718: Catching too general exception Exception (broad-exception-caught)
client/backend/app.py:182:15: W0718: Catching too general exception Exception (broad-exception-caught)
client/backend/app.py:209:15: W0718: Catching too general exception Exception (broad-exception-caught)
client/backend/app.py:187:12: C0415: Import outside toplevel (json) (import-outside-toplevel)
client/backend/app.py:188:12: R1705: Unnecessary "else" after "return", remove the "else" and de-indent the code inside it (no-else-return)
client/backend/app.py:260:11: W0718: Catching too general exception Exception (broad-exception-caught)
client/backend/app.py:260:4: W0612: Unused variable 'e' (unused-variable)
client/file-sync-client.py:14:0: C0411: standard import "datetime.datetime" should be placed before third party import "paramiko" (wrong-import-order)
client/backend/app.py:6:0: C0411: standard import "logging" should be placed before third party imports "paramiko", "dotenv.load_dotenv" (wrong-import-order)
client/backend/app.py:7:0: C0411: standard import "os" should be placed before third party imports "paramiko", "dotenv.load_dotenv" (wrong-import-order)
client/backend/app.py:8:0: C0411: standard import "sys" should be placed before third party imports "paramiko", "dotenv.load_dotenv" (wrong-import-order)
client/backend/app.py:9:0: C0411: standard import "traceback" should be placed before third party imports "paramiko", "dotenv.load_dotenv" (wrong-import-order)
client/backend/app.py:10:0: C0411: standard import "datetime.datetime" should be placed before third party imports "paramiko", "dotenv.load_dotenv" (wrong-import-order)
client/backend/app.py:6:0: C0412: Imports from package logging are not grouped (ungrouped-imports)
client/backend/app.py:7:0: C0412: Imports from package os are not grouped (ungrouped-imports)
client/backend/app.py:8:0: C0412: Imports from package sys are not grouped (ungrouped-imports)
client/backend/app.py:10:0: C0412: Imports from package datetime are not grouped (ungrouped-imports)
client/backend/app.py:13:0: C0412: Imports from package dotenv are not grouped (ungrouped-imports)
client/backend/app.py:11:0: W0611: Unused send_from_directory imported from flask (unused-import)
************* Module client.backend.ai_model
client/backend/ai_model.py:39:0: C0103: Constant name "_gpt4all_model" doesn't conform to UPPER_CASE naming style (invalid-name)
client/backend/ai_model.py:40:0: C0103: Constant name "_openai" doesn't conform to UPPER_CASE naming style (invalid-name)
client/backend/ai_model.py:41:0: C0103: Constant name "_gemini" doesn't conform to UPPER_CASE naming style (invalid-name)
client/backend/ai_model.py:42:0: C0103: Constant name "_huggingface_pipeline" doesn't conform to UPPER_CASE naming style (invalid-name)
client/backend/ai_model.py:43:0: C0103: Constant name "_huggingface_tokenizer" doesn't conform to UPPER_CASE naming style (invalid-name)
client/backend/ai_model.py:44:0: C0103: Constant name "_huggingface_model" doesn't conform to UPPER_CASE naming style (invalid-name)
client/backend/ai_model.py:49:4: W0107: Unnecessary pass statement (unnecessary-pass)
client/backend/ai_model.py:58:4: W0603: Using the global statement (global-statement)
client/backend/ai_model.py:96:11: W0718: Catching too general exception Exception (broad-exception-caught)
client/backend/ai_model.py:70:12: W0612: Unused variable 'filename' (unused-variable)
client/backend/ai_model.py:96:4: W0612: Unused variable 'e' (unused-variable)
client/backend/ai_model.py:107:4: W0603: Using the global statement (global-statement)
client/backend/ai_model.py:121:11: W0718: Catching too general exception Exception (broad-exception-caught)
client/backend/ai_model.py:116:8: C0415: Import outside toplevel (openai) (import-outside-toplevel)
client/backend/ai_model.py:121:4: W0612: Unused variable 'e' (unused-variable)
client/backend/ai_model.py:132:4: W0603: Using the global statement (global-statement)
client/backend/ai_model.py:146:11: W0718: Catching too general exception Exception (broad-exception-caught)
client/backend/ai_model.py:141:8: C0415: Import outside toplevel (google.generativeai) (import-outside-toplevel)
client/backend/ai_model.py:146:4: W0612: Unused variable 'e' (unused-variable)
client/backend/ai_model.py:157:4: W0603: Using the global statement (global-statement)
client/backend/ai_model.py:205:11: W0718: Catching too general exception Exception (broad-exception-caught)
client/backend/ai_model.py:205:4: W0612: Unused variable 'e' (unused-variable)
client/backend/ai_model.py:210:14: W0621: Redefining name 'model_name' from outer scope (line 505) (redefined-outer-name)
client/backend/ai_model.py:224:4: R1705: Unnecessary "elif" after "return", remove the leading "el" from "elif" (no-else-return)
client/backend/ai_model.py:265:0: W0621: Redefining name 'model_name' from outer scope (line 505) (redefined-outer-name)
client/backend/ai_model.py:294:11: W0718: Catching too general exception Exception (broad-exception-caught)
client/backend/ai_model.py:298:4: W0612: Unused variable 'elapsed_time' (unused-variable)
client/backend/ai_model.py:329:4: W0612: Unused variable 'e' (unused-variable)
client/backend/ai_model.py:351:19: E1101: Module 'openai' has no 'ChatCompletion' member (no-member)
client/backend/ai_model.py:366:4: W0612: Unused variable 'e' (unused-variable)
client/backend/ai_model.py:392:4: W0612: Unused variable 'e' (unused-variable)
client/backend/ai_model.py:406:4: W0612: Unused variable 'model' (unused-variable)
client/backend/ai_model.py:406:11: W0612: Unused variable 'tokenizer' (unused-variable)
client/backend/ai_model.py:431:4: W0612: Unused variable 'e' (unused-variable)
client/backend/ai_model.py:442:4: W0621: Redefining name 'models' from outer scope (line 499) (redefined-outer-name)
client/backend/ai_model.py:453:11: W0718: Catching too general exception Exception (broad-exception-caught)
client/backend/ai_model.py:486:11: W0718: Catching too general exception Exception (broad-exception-caught)
client/backend/ai_model.py:508:12: C0103: Constant name "test_log" doesn't conform to UPPER_CASE naming style (invalid-name)
client/backend/ai_model.py:10:0: W0611: Unused Union imported from typing (unused-import)
************* Module client.backend.gpt4all.app
client/backend/gpt4all/app.py:6:0: W0105: String statement has no effect (pointless-string-statement)
client/backend/gpt4all/app.py:12:0: C0413: Import "import importlib.metadata" should be placed at the top of the module (wrong-import-position)
client/backend/gpt4all/app.py:13:0: C0413: Import "import io" should be placed at the top of the module (wrong-import-position)
client/backend/gpt4all/app.py:14:0: C0413: Import "import sys" should be placed at the top of the module (wrong-import-position)
client/backend/gpt4all/app.py:15:0: C0413: Import "from collections import namedtuple" should be placed at the top of the module (wrong-import-position)
client/backend/gpt4all/app.py:16:0: C0413: Import "from typing_extensions import Annotated" should be placed at the top of the module (wrong-import-position)
client/backend/gpt4all/app.py:18:0: C0413: Import "import typer" should be placed at the top of the module (wrong-import-position)
client/backend/gpt4all/app.py:19:0: C0413: Import "from gpt4all import GPT4All" should be placed at the top of the module (wrong-import-position)
client/backend/gpt4all/app.py:94:8: W0621: Redefining name 'version' from outer scope (line 185) (redefined-outer-name)
client/backend/gpt4all/app.py:98:4: W0702: No exception type(s) specified (bare-except)
************* Module patch.ailinux-alpha-patch-v0.6
patch/ailinux-alpha-patch-v0.6.py:70:0: C0303: Trailing whitespace (trailing-whitespace)
patch/ailinux-alpha-patch-v0.6.py:89:0: C0303: Trailing whitespace (trailing-whitespace)
patch/ailinux-alpha-patch-v0.6.py:126:0: C0303: Trailing whitespace (trailing-whitespace)
patch/ailinux-alpha-patch-v0.6.py:144:0: C0303: Trailing whitespace (trailing-whitespace)
patch/ailinux-alpha-patch-v0.6.py:187:0: C0303: Trailing whitespace (trailing-whitespace)
patch/ailinux-alpha-patch-v0.6.py:189:0: C0303: Trailing whitespace (trailing-whitespace)
patch/ailinux-alpha-patch-v0.6.py:195:0: C0303: Trailing whitespace (trailing-whitespace)
patch/ailinux-alpha-patch-v0.6.py:208:0: C0301: Line too long (102/100) (line-too-long)
patch/ailinux-alpha-patch-v0.6.py:238:0: C0303: Trailing whitespace (trailing-whitespace)
patch/ailinux-alpha-patch-v0.6.py:240:0: C0303: Trailing whitespace (trailing-whitespace)
patch/ailinux-alpha-patch-v0.6.py:247:0: C0303: Trailing whitespace (trailing-whitespace)
patch/ailinux-alpha-patch-v0.6.py:255:0: C0303: Trailing whitespace (trailing-whitespace)
patch/ailinux-alpha-patch-v0.6.py:259:0: C0303: Trailing whitespace (trailing-whitespace)
patch/ailinux-alpha-patch-v0.6.py:270:0: C0303: Trailing whitespace (trailing-whitespace)
patch/ailinux-alpha-patch-v0.6.py:272:0: C0303: Trailing whitespace (trailing-whitespace)
patch/ailinux-alpha-patch-v0.6.py:279:0: C0303: Trailing whitespace (trailing-whitespace)
patch/ailinux-alpha-patch-v0.6.py:285:0: C0303: Trailing whitespace (trailing-whitespace)
patch/ailinux-alpha-patch-v0.6.py:357:0: C0301: Line too long (115/100) (line-too-long)
patch/ailinux-alpha-patch-v0.6.py:373:74: C0303: Trailing whitespace (trailing-whitespace)
patch/ailinux-alpha-patch-v0.6.py:375:57: C0303: Trailing whitespace (trailing-whitespace)
patch/ailinux-alpha-patch-v0.6.py:377:39: C0303: Trailing whitespace (trailing-whitespace)
patch/ailinux-alpha-patch-v0.6.py:1:0: C0103: Module name "6" doesn't conform to snake_case naming style (invalid-name)
patch/ailinux-alpha-patch-v0.6.py:23:0: R0903: Too few public methods (1/2) (too-few-public-methods)
patch/ailinux-alpha-patch-v0.6.py:36:0: R0902: Too many instance attributes (8/7) (too-many-instance-attributes)
patch/ailinux-alpha-patch-v0.6.py:49:8: C0415: Import outside toplevel (logging) (import-outside-toplevel)
patch/ailinux-alpha-patch-v0.6.py:68:16: W1203: Use lazy % formatting in logging functions (logging-fstring-interpolation)
patch/ailinux-alpha-patch-v0.6.py:78:12: W1203: Use lazy % formatting in logging functions (logging-fstring-interpolation)
patch/ailinux-alpha-patch-v0.6.py:82:12: W1203: Use lazy % formatting in logging functions (logging-fstring-interpolation)
patch/ailinux-alpha-patch-v0.6.py:100:8: R1705: Unnecessary "elif" after "return", remove the leading "el" from "elif" (no-else-return)
patch/ailinux-alpha-patch-v0.6.py:110:12: R1705: Unnecessary "elif" after "return", remove the leading "el" from "elif" (no-else-return)
patch/ailinux-alpha-patch-v0.6.py:84:4: R0911: Too many return statements (7/6) (too-many-return-statements)
patch/ailinux-alpha-patch-v0.6.py:155:8: R1705: Unnecessary "elif" after "return", remove the leading "el" from "elif" (no-else-return)
patch/ailinux-alpha-patch-v0.6.py:179:4: R0914: Too many local variables (19/15) (too-many-locals)
patch/ailinux-alpha-patch-v0.6.py:318:16: W1203: Use lazy % formatting in logging functions (logging-fstring-interpolation)
patch/ailinux-alpha-patch-v0.6.py:322:16: W1203: Use lazy % formatting in logging functions (logging-fstring-interpolation)
patch/ailinux-alpha-patch-v0.6.py:329:8: W1201: Use lazy % formatting in logging functions (logging-not-lazy)
patch/ailinux-alpha-patch-v0.6.py:330:8: W1203: Use lazy % formatting in logging functions (logging-fstring-interpolation)
patch/ailinux-alpha-patch-v0.6.py:330:25: W1309: Using an f-string that does not have any interpolated variables (f-string-without-interpolation)
patch/ailinux-alpha-patch-v0.6.py:331:8: W1203: Use lazy % formatting in logging functions (logging-fstring-interpolation)
patch/ailinux-alpha-patch-v0.6.py:332:8: W1203: Use lazy % formatting in logging functions (logging-fstring-interpolation)
patch/ailinux-alpha-patch-v0.6.py:333:8: W1203: Use lazy % formatting in logging functions (logging-fstring-interpolation)
patch/ailinux-alpha-patch-v0.6.py:345:16: W1203: Use lazy % formatting in logging functions (logging-fstring-interpolation)
patch/ailinux-alpha-patch-v0.6.py:288:4: R0912: Too many branches (16/12) (too-many-branches)
patch/ailinux-alpha-patch-v0.6.py:415:4: C0415: Import outside toplevel (difflib) (import-outside-toplevel)
patch/ailinux-alpha-patch-v0.6.py:416:4: C0415: Import outside toplevel (time) (import-outside-toplevel)
patch/ailinux-alpha-patch-v0.6.py:441:19: W0718: Catching too general exception Exception (broad-exception-caught)
patch/ailinux-alpha-patch-v0.6.py:20:0: W0611: Unused Tuple imported from typing (unused-import)
patch/ailinux-alpha-patch-v0.6.py:20:0: W0611: Unused Optional imported from typing (unused-import)
patch/ailinux-alpha-patch-v0.6.py:20:0: W0611: Unused Any imported from typing (unused-import)
************* Module patch.ailinux-alpha-patch-v0.3
patch/ailinux-alpha-patch-v0.3.py:1:0: C0103: Module name "3" doesn't conform to snake_case naming style (invalid-name)
patch/ailinux-alpha-patch-v0.3.py:59:11: W0718: Catching too general exception Exception (broad-exception-caught)
patch/ailinux-alpha-patch-v0.3.py:94:11: W0718: Catching too general exception Exception (broad-exception-caught)
patch/ailinux-alpha-patch-v0.3.py:200:11: W0718: Catching too general exception Exception (broad-exception-caught)
patch/ailinux-alpha-patch-v0.3.py:590:11: W0718: Catching too general exception Exception (broad-exception-caught)
patch/ailinux-alpha-patch-v0.3.py:614:11: W0718: Catching too general exception Exception (broad-exception-caught)
patch/ailinux-alpha-patch-v0.3.py:598:8: C0415: Import outside toplevel (subprocess) (import-outside-toplevel)
patch/ailinux-alpha-patch-v0.3.py:601:17: W1510: 'subprocess.run' used without explicitly defining the value for 'check'. (subprocess-run-check)
patch/ailinux-alpha-patch-v0.3.py:603:8: R1705: Unnecessary "else" after "return", remove the "else" and de-indent the code inside it (no-else-return)
************* Module server.backend.websocket-server
server/backend/websocket-server.py:63:0: C0301: Line too long (103/100) (line-too-long)
server/backend/websocket-server.py:147:0: C0303: Trailing whitespace (trailing-whitespace)
server/backend/websocket-server.py:154:0: C0303: Trailing whitespace (trailing-whitespace)
server/backend/websocket-server.py:162:0: C0303: Trailing whitespace (trailing-whitespace)
server/backend/websocket-server.py:174:0: C0303: Trailing whitespace (trailing-whitespace)
server/backend/websocket-server.py:203:0: C0303: Trailing whitespace (trailing-whitespace)
server/backend/websocket-server.py:213:0: C0303: Trailing whitespace (trailing-whitespace)
server/backend/websocket-server.py:216:0: C0303: Trailing whitespace (trailing-whitespace)
server/backend/websocket-server.py:220:0: C0303: Trailing whitespace (trailing-whitespace)
server/backend/websocket-server.py:230:0: C0301: Line too long (104/100) (line-too-long)
server/backend/websocket-server.py:231:0: C0303: Trailing whitespace (trailing-whitespace)
server/backend/websocket-server.py:234:0: C0303: Trailing whitespace (trailing-whitespace)
server/backend/websocket-server.py:247:0: C0303: Trailing whitespace (trailing-whitespace)
server/backend/websocket-server.py:264:0: C0301: Line too long (103/100) (line-too-long)
server/backend/websocket-server.py:265:0: C0303: Trailing whitespace (trailing-whitespace)
server/backend/websocket-server.py:278:0: C0303: Trailing whitespace (trailing-whitespace)
server/backend/websocket-server.py:287:0: C0303: Trailing whitespace (trailing-whitespace)
server/backend/websocket-server.py:291:0: C0303: Trailing whitespace (trailing-whitespace)
server/backend/websocket-server.py:303:0: C0303: Trailing whitespace (trailing-whitespace)
server/backend/websocket-server.py:306:0: C0303: Trailing whitespace (trailing-whitespace)
server/backend/websocket-server.py:310:0: C0301: Line too long (102/100) (line-too-long)
server/backend/websocket-server.py:317:0: C0303: Trailing whitespace (trailing-whitespace)
server/backend/websocket-server.py:321:0: C0303: Trailing whitespace (trailing-whitespace)
server/backend/websocket-server.py:337:0: C0303: Trailing whitespace (trailing-whitespace)
server/backend/websocket-server.py:339:0: C0301: Line too long (104/100) (line-too-long)
server/backend/websocket-server.py:357:0: C0303: Trailing whitespace (trailing-whitespace)
server/backend/websocket-server.py:370:0: C0303: Trailing whitespace (trailing-whitespace)
server/backend/websocket-server.py:374:0: C0301: Line too long (112/100) (line-too-long)
server/backend/websocket-server.py:376:0: C0303: Trailing whitespace (trailing-whitespace)
server/backend/websocket-server.py:383:0: C0301: Line too long (129/100) (line-too-long)
server/backend/websocket-server.py:384:0: C0303: Trailing whitespace (trailing-whitespace)
server/backend/websocket-server.py:387:0: C0303: Trailing whitespace (trailing-whitespace)
server/backend/websocket-server.py:406:27: C0303: Trailing whitespace (trailing-whitespace)
server/backend/websocket-server.py:409:13: C0303: Trailing whitespace (trailing-whitespace)
server/backend/websocket-server.py:416:0: C0301: Line too long (117/100) (line-too-long)
server/backend/websocket-server.py:417:0: C0303: Trailing whitespace (trailing-whitespace)
server/backend/websocket-server.py:420:0: C0303: Trailing whitespace (trailing-whitespace)
server/backend/websocket-server.py:438:0: C0303: Trailing whitespace (trailing-whitespace)
server/backend/websocket-server.py:1:0: C0103: Module name "websocket-server" doesn't conform to snake_case naming style (invalid-name)
server/backend/websocket-server.py:34:11: W1508: os.getenv default type is builtins.int. Expected str or None. (invalid-envvar-default)
server/backend/websocket-server.py:176:8: W1203: Use lazy % formatting in logging functions (logging-fstring-interpolation)
server/backend/websocket-server.py:184:0: R0913: Too many arguments (6/5) (too-many-arguments)
server/backend/websocket-server.py:184:0: R0917: Too many positional arguments (6/5) (too-many-positional-arguments)
server/backend/websocket-server.py:232:11: W0718: Catching too general exception Exception (broad-exception-caught)
server/backend/websocket-server.py:230:8: W1203: Use lazy % formatting in logging functions (logging-fstring-interpolation)
server/backend/websocket-server.py:233:8: W1203: Use lazy % formatting in logging functions (logging-fstring-interpolation)
server/backend/websocket-server.py:340:11: W0718: Catching too general exception Exception (broad-exception-caught)
server/backend/websocket-server.py:267:8: W1203: Use lazy % formatting in logging functions (logging-fstring-interpolation)
server/backend/websocket-server.py:280:12: W1203: Use lazy % formatting in logging functions (logging-fstring-interpolation)
server/backend/websocket-server.py:284:12: W1203: Use lazy % formatting in logging functions (logging-fstring-interpolation)
server/backend/websocket-server.py:296:20: W1203: Use lazy % formatting in logging functions (logging-fstring-interpolation)
server/backend/websocket-server.py:329:19: W0718: Catching too general exception Exception (broad-exception-caught)
server/backend/websocket-server.py:310:20: W1203: Use lazy % formatting in logging functions (logging-fstring-interpolation)
server/backend/websocket-server.py:323:16: W1203: Use lazy % formatting in logging functions (logging-fstring-interpolation)
server/backend/websocket-server.py:330:16: W1203: Use lazy % formatting in logging functions (logging-fstring-interpolation)
server/backend/websocket-server.py:339:8: W1203: Use lazy % formatting in logging functions (logging-fstring-interpolation)
server/backend/websocket-server.py:341:8: W1203: Use lazy % formatting in logging functions (logging-fstring-interpolation)
server/backend/websocket-server.py:349:12: W1203: Use lazy % formatting in logging functions (logging-fstring-interpolation)
server/backend/websocket-server.py:255:0: R0912: Too many branches (14/12) (too-many-branches)
server/backend/websocket-server.py:255:0: R0915: Too many statements (53/50) (too-many-statements)
server/backend/websocket-server.py:255:40: W0613: Unused argument 'path' (unused-argument)
server/backend/websocket-server.py:385:15: W0718: Catching too general exception Exception (broad-exception-caught)
server/backend/websocket-server.py:365:16: W1203: Use lazy % formatting in logging functions (logging-fstring-interpolation)
server/backend/websocket-server.py:383:16: W1203: Use lazy % formatting in logging functions (logging-fstring-interpolation)
server/backend/websocket-server.py:386:12: W1203: Use lazy % formatting in logging functions (logging-fstring-interpolation)
server/backend/websocket-server.py:394:4: W0601: Global variable 'server_start_time' undefined at the module level (global-variable-undefined)
server/backend/websocket-server.py:402:8: W1203: Use lazy % formatting in logging functions (logging-fstring-interpolation)
server/backend/websocket-server.py:405:15: E1101: Module 'websockets' has no 'serve' member (no-member)
server/backend/websocket-server.py:416:8: W1203: Use lazy % formatting in logging functions (logging-fstring-interpolation)
server/backend/websocket-server.py:419:8: W0612: Unused variable 'cleanup_task' (unused-variable)
server/backend/websocket-server.py:443:11: W0718: Catching too general exception Exception (broad-exception-caught)
server/backend/websocket-server.py:444:8: W1203: Use lazy % formatting in logging functions (logging-fstring-interpolation)
server/backend/websocket-server.py:13:0: W0611: Unused Set imported from typing (unused-import)
server/backend/websocket-server.py:13:0: W0611: Unused Optional imported from typing (unused-import)
************* Module server.backend.ai_model
server/backend/ai_model.py:1:1: W0511: TODO: Dieses Modul enthält Code, der in anderen Dateien dupliziert ist. (fixme)
server/backend/ai_model.py:42:0: C0103: Constant name "_gpt4all_model" doesn't conform to UPPER_CASE naming style (invalid-name)
server/backend/ai_model.py:43:0: C0103: Constant name "_openai" doesn't conform to UPPER_CASE naming style (invalid-name)
server/backend/ai_model.py:44:0: C0103: Constant name "_gemini" doesn't conform to UPPER_CASE naming style (invalid-name)
server/backend/ai_model.py:45:0: C0103: Constant name "_huggingface_pipeline" doesn't conform to UPPER_CASE naming style (invalid-name)
server/backend/ai_model.py:46:0: C0103: Constant name "_huggingface_tokenizer" doesn't conform to UPPER_CASE naming style (invalid-name)
server/backend/ai_model.py:47:0: C0103: Constant name "_huggingface_model" doesn't conform to UPPER_CASE naming style (invalid-name)
server/backend/ai_model.py:52:4: W0107: Unnecessary pass statement (unnecessary-pass)
server/backend/ai_model.py:61:4: W0603: Using the global statement (global-statement)
server/backend/ai_model.py:99:11: W0718: Catching too general exception Exception (broad-exception-caught)
server/backend/ai_model.py:73:12: W0612: Unused variable 'filename' (unused-variable)
server/backend/ai_model.py:99:4: W0612: Unused variable 'e' (unused-variable)
server/backend/ai_model.py:110:4: W0603: Using the global statement (global-statement)
server/backend/ai_model.py:124:11: W0718: Catching too general exception Exception (broad-exception-caught)
server/backend/ai_model.py:119:8: C0415: Import outside toplevel (openai) (import-outside-toplevel)
server/backend/ai_model.py:124:4: W0612: Unused variable 'e' (unused-variable)
server/backend/ai_model.py:135:4: W0603: Using the global statement (global-statement)
server/backend/ai_model.py:149:11: W0718: Catching too general exception Exception (broad-exception-caught)
server/backend/ai_model.py:144:8: C0415: Import outside toplevel (google.generativeai) (import-outside-toplevel)
server/backend/ai_model.py:149:4: W0612: Unused variable 'e' (unused-variable)
server/backend/ai_model.py:160:4: W0603: Using the global statement (global-statement)
server/backend/ai_model.py:208:11: W0718: Catching too general exception Exception (broad-exception-caught)
server/backend/ai_model.py:208:4: W0612: Unused variable 'e' (unused-variable)
server/backend/ai_model.py:213:14: W0621: Redefining name 'model_name' from outer scope (line 508) (redefined-outer-name)
server/backend/ai_model.py:227:4: R1705: Unnecessary "elif" after "return", remove the leading "el" from "elif" (no-else-return)
server/backend/ai_model.py:268:0: W0621: Redefining name 'model_name' from outer scope (line 508) (redefined-outer-name)
server/backend/ai_model.py:297:11: W0718: Catching too general exception Exception (broad-exception-caught)
server/backend/ai_model.py:301:4: W0612: Unused variable 'elapsed_time' (unused-variable)
server/backend/ai_model.py:332:4: W0612: Unused variable 'e' (unused-variable)
server/backend/ai_model.py:354:19: E1101: Module 'openai' has no 'ChatCompletion' member (no-member)
server/backend/ai_model.py:369:4: W0612: Unused variable 'e' (unused-variable)
server/backend/ai_model.py:395:4: W0612: Unused variable 'e' (unused-variable)
server/backend/ai_model.py:409:4: W0612: Unused variable 'model' (unused-variable)
server/backend/ai_model.py:409:11: W0612: Unused variable 'tokenizer' (unused-variable)
server/backend/ai_model.py:434:4: W0612: Unused variable 'e' (unused-variable)
server/backend/ai_model.py:445:4: W0621: Redefining name 'models' from outer scope (line 502) (redefined-outer-name)
server/backend/ai_model.py:456:11: W0718: Catching too general exception Exception (broad-exception-caught)
server/backend/ai_model.py:489:11: W0718: Catching too general exception Exception (broad-exception-caught)
server/backend/ai_model.py:511:12: C0103: Constant name "test_log" doesn't conform to UPPER_CASE naming style (invalid-name)
server/backend/ai_model.py:13:0: W0611: Unused Union imported from typing (unused-import)
server/backend/ai_model.py:1:0: R0801: Similar lines in 2 files
==client.backend.ai_model:[13:513]
==server.backend.ai_model:[16:516]
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(name)s - %(message)s",
    handlers=[
        logging.FileHandler("ai_model.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger("AIModel")

# Load environment variables
load_dotenv()

# Get API keys and model paths from environment
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "")
HUGGINGFACE_API_KEY = os.getenv("HUGGINGFACE_API_KEY", "")
LLAMA_MODEL_PATH = os.getenv("LLAMA_MODEL_PATH", "Meta-Llama-3-8B-Instruct.Q4_0.gguf")
DEFAULT_MODEL = os.getenv("DEFAULT_MODEL", "gpt4all")

# Hugging Face model configuration
HUGGINGFACE_MODEL_ID = os.getenv("HUGGINGFACE_MODEL_ID", "mistralai/Mistral-7B-Instruct-v0.2")
CACHE_DIR = os.getenv("HUGGINGFACE_CACHE_DIR", "./models/huggingface")

# Global model instances
_gpt4all_model = None
_openai = None
_gemini = None
_huggingface_pipeline = None
_huggingface_tokenizer = None
_huggingface_model = None


class ModelNotInitializedError(Exception):
    """Exception raised when a model cannot be initialized."""
    pass


def initialize_gpt4all():
    """Initialize the GPT4All model for offline processing.

    Returns:
        GPT4All model instance or None if initialization fails
    """
    global _gpt4all_model
    if _gpt4all_model is not None:
        return _gpt4all_model

    try:
        # pylint: disable=C0415  # Import außerhalb des Toplevel
        from gpt4all import GPT4All

        # Check if model exists
        model_path = os.path.expanduser(LLAMA_MODEL_PATH)
        if not os.path.exists(model_path):
            model_dir = os.path.dirname(model_path)
            filename = os.path.basename(model_path)
            logger.warning("Model file not found at: %smodel_path")
            logger.info("Checking if model exists in directory: %smodel_dir")

            # Check if the directory exists, create if not
            if not os.path.exists(model_dir):
                os.makedirs(model_dir, exist_ok=True)
                logger.info("Created model directory: %smodel_dir")

            # List available models if directory exists
            if os.path.exists(model_dir):
                files = os.listdir(model_dir)
                gguf_files = [f for f in files if f.endswith('.gguf')]
                if gguf_files:
                    # Use the first available .gguf file
                    model_path = os.path.join(model_dir, gguf_files[0])
                    logger.info("Using available model: %smodel_path")
                else:
                    logger.warning("No .gguf models found. Will download the default model.")

            # Model will be downloaded automatically by GPT4All if not found

        logger.info("Loading GPT4All model from: %smodel_path")
        _gpt4all_model = GPT4All(model_path)
        logger.info("GPT4All model loaded successfully")
        return _gpt4all_model
    except Exception as e:
        logger.error("Error initializing GPT4All: %sstr(e)")
        return None


def initialize_openai():
    """Initialize the OpenAI API client.

    Returns:
        OpenAI client object or None if initialization fails
    """
    global _openai
    if _openai is not None:
        return _openai

    if not OPENAI_API_KEY:
        logger.warning("No OpenAI API key found in environment")
        return None

    try:
        import openai
        openai.api_key = OPENAI_API_KEY
        _openai = openai
        logger.info("OpenAI API initialized successfully")
        return _openai
    except Exception as e:
        logger.error("Error initializing OpenAI API: %sstr(e)")
        return None


def initialize_gemini():
    """Initialize the Google Gemini API client.

    Returns:
        Gemini client object or None if initialization fails
    """
    global _gemini
    if _gemini is not None:
        return _gemini

    if not GEMINI_API_KEY:
        logger.warning("No Gemini API key found in environment")
        return None

    try:
        import google.generativeai as genai
        genai.configure(api_key=GEMINI_API_KEY)
        _gemini = genai
        logger.info("Google Gemini API initialized successfully")
        return _gemini
    except Exception as e:
        logger.error("Error initializing Gemini API: %sstr(e)")
        return None


def initialize_huggingface():
    """Initialize the Hugging Face model for inference.

    Returns:
        A tuple of (model, tokenizer, pipeline) or None if initialization fails
    """
    global _huggingface_model, _huggingface_tokenizer, _huggingface_pipeline

    if _huggingface_pipeline is not None:
        return _huggingface_model, _huggingface_tokenizer, _huggingface_pipeline

    try:
        # pylint: disable=C0415  # Import außerhalb des Toplevel
        from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline
        import torch

        # Create cache directory if it doesn't exist
        os.makedirs(CACHE_DIR, exist_ok=True)

        # Check for CUDA availability
        device = "cuda" if torch.cuda.is_available() else "cpu"
        logger.info("Using device: %sdevice for Hugging Face model")

        # Load tokenizer first
        logger.info("Loading Hugging Face tokenizer: %sHUGGINGFACE_MODEL_ID")
        _huggingface_tokenizer = AutoTokenizer.from_pretrained(
            HUGGINGFACE_MODEL_ID,
            cache_dir=CACHE_DIR,
            token=HUGGINGFACE_API_KEY if HUGGINGFACE_API_KEY else None
        )

        # Load model with appropriate configuration
        logger.info("Loading Hugging Face model: %sHUGGINGFACE_MODEL_ID")
        _huggingface_model = AutoModelForCausalLM.from_pretrained(
            HUGGINGFACE_MODEL_ID,
            cache_dir=CACHE_DIR,
            token=HUGGINGFACE_API_KEY if HUGGINGFACE_API_KEY else None,
            torch_dtype=torch.float16 if device == "cuda" else torch.float32,
            low_cpu_mem_usage=True,
            device_map="auto" if device == "cuda" else None
        )

        # Create text generation pipeline
        logger.info("Creating Hugging Face pipeline")
        _huggingface_pipeline = pipeline(
            "text-generation",
            model=_huggingface_model,
            tokenizer=_huggingface_tokenizer,
            device=0 if device == "cuda" else -1
        )

        logger.info("Hugging Face model initialized successfully")
        return _huggingface_model, _huggingface_tokenizer, _huggingface_pipeline

    except Exception as e:
        logger.error("Error initializing Hugging Face model: %sstr(e)")
        return None, None, None


def get_model(model_name: str):
    """Get the requested AI model.

    Args:
        model_name: Name of the model to use ('gpt4all', 'openai', 'gemini', 'huggingface')

    Returns:
        Model instance or None if initialization fails

    Raises:
        ValueError: If an unknown model name is provided
    """
    model_name = model_name.lower()

    if model_name == "gpt4all":
        return initialize_gpt4all()
    elif model_name == "openai":
        return initialize_openai()
    elif model_name == "gemini":
        return initialize_gemini()
    elif model_name == "huggingface":
        return initialize_huggingface()
    else:
        raise ValueError(f"Unknown model: {model_name}")


def create_prompt(log_text: str, instruction: Optional[str] = None) -> str:
    """Create a standardized prompt for log analysis.

    Args:
        log_text: The log text to analyze
        instruction: Optional specific instruction to override default

    Returns:
        Formatted prompt string
    """
    default_instruction = """Analyze the following log and provide insights:
1. Summarize what the log is showing
2. Identify any errors or warnings
3. Suggest potential solutions if problems are found
"""

    instruction = instruction or default_instruction

    return f"""{instruction}

LOG:
{log_text}

ANALYSIS:
"""


def analyze_log(log_text: str,

model_name: str = DEFAULT_MODEL,
instruction: Optional[str] = None) -> str:
    """Analyze log text using the specified AI model.

    Args:
        log_text: The log text to analyze
        model_name: Name of the model to use for analysis
        instruction: Optional specific instruction for the model

    Returns:
        Analysis result as a string
    """
    start_time = time.time()
    logger.info("Analyzing log with model: %smodel_name")

    # Create the prompt
    prompt = create_prompt(log_text, instruction)

    try:
        if model_name == "gpt4all":
            response = gpt4all_response(prompt)
        elif model_name == "openai":
            response = openai_response(prompt)
        elif model_name == "gemini":
            response = gemini_response(prompt)
        elif model_name == "huggingface":
            response = huggingface_response(prompt)
        else:
            return f"⚠ Error: Unknown model '{model_name}' specified"
    except Exception as e:
        logger.exception("Error analyzing log with %smodel_name: %sstr(e)")
        return f"⚠ Error analyzing log: {str(e)}"

    elapsed_time = time.time() - start_time
    logger.info("Log analysis completed in %selapsed_time:.2f seconds")

    return response


def gpt4all_response(prompt: str) -> str:
    """Get a response from the GPT4All model.

    Args:
        prompt: The prompt to send to the model

    Returns:
        Model response as a string
    """
    model = initialize_gpt4all()
    if not model:
        raise ModelNotInitializedError("GPT4All model could not be initialized")

    try:
        logger.debug("Sending prompt to GPT4All (length: %slen(prompt))")
        response = ""

        # Use with context for proper resource handling
        with model.chat_session():
            # Stream response tokens for better performance monitoring
            for token in model.generate(prompt, max_tokens=2048, temp=0.7):
                response += token

        logger.debug("Received GPT4All response (length: %slen(response))")
        return response.strip()
    except Exception as e:
        logger.exception("Error with GPT4All: %sstr(e)")
        raise


def openai_response(prompt: str) -> str:
    """Get a response from the OpenAI API.

    Args:
        prompt: The prompt to send to the model

    Returns:
        Model response as a string
    """
    openai = initialize_openai()
    if not openai:
        raise ModelNotInitializedError("OpenAI API could not be initialized. Check your API key.")

    try:
        logger.debug("Sending prompt to OpenAI (length: %slen(prompt))")

        # Use the ChatCompletion API
        response = openai.ChatCompletion.create(
            model="gpt-4",

            messages=[
                {"role": "system", "content": "" +
                    "You are a log analysis expert. Provide clear, concise analysis of log files."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=1024,
            temperature=0.5
        )

        response_text = response["choices"][0]["message"]["content"].strip()
        logger.debug("Received OpenAI response (length: %slen(response_text))")
        return response_text
    except Exception as e:
        logger.exception("Error with OpenAI: %sstr(e)")
        raise


def gemini_response(prompt: str) -> str:
    """Get a response from the Google Gemini API.

    Args:
        prompt: The prompt to send to the model

    Returns:
        Model response as a string
    """
    gemini = initialize_gemini()
    if not gemini:
        raise ModelNotInitializedError("Gemini API could not be initialized. Check your API key.")

    try:
        logger.debug("Sending prompt to Gemini (length: %slen(prompt))")
        model = gemini.GenerativeModel('gemini-pro')
        response = model.generate_content(prompt)

        response_text = response.text
        logger.debug("Received Gemini response (length: %slen(response_text))")
        return response_text.strip()
    except Exception as e:
        logger.exception("Error with Gemini: %sstr(e)")
        raise


def huggingface_response(prompt: str) -> str:
    """Get a response from the Hugging Face model.

    Args:
        prompt: The prompt to send to the model

    Returns:
        Model response as a string
    """
    model, tokenizer, pipe = initialize_huggingface()
    if not pipe:
        raise ModelNotInitializedError("Hugging Face model could not be initialized.")

    try:
        logger.debug("Sending prompt to Hugging Face (length: %slen(prompt))")

        # Generate text with appropriate parameters
        outputs = pipe(
            prompt,
            max_new_tokens=1024,
            temperature=0.7,
            top_p=0.95,
            repetition_penalty=1.15,
            do_sample=True
        )

        # Extract the generated text
        generated_text = outputs[0]['generated_text']

        # Remove the prompt from the response
        response_text = generated_text[len(prompt):].strip()

        logger.debug("Received Hugging Face response (length: %slen(response_text))")
        return response_text
    except Exception as e:
        logger.exception("Error with Hugging Face: %sstr(e)")
        raise


def get_available_models() -> List[Dict[str, Any]]:
    """Get information about available models.

    Returns:
        List of dictionaries with model information
    """
    models = []

    # Check GPT4All
    try:
        gpt4all = initialize_gpt4all()
        models.append({
            "name": "gpt4all",
            "available": gpt4all is not None,
            "type": "local",
            "file": LLAMA_MODEL_PATH
        })
    except Exception:
        models.append({
            "name": "gpt4all",
            "available": False,
            "type": "local",
            "error": "Failed to initialize"
        })

    # Check OpenAI
    models.append({
        "name": "openai",
        "available": OPENAI_API_KEY != "",
        "type": "api",
        "model": "gpt-4"
    })

    # Check Gemini
    models.append({
        "name": "gemini",
        "available": GEMINI_API_KEY != "",
        "type": "api",
        "model": "gemini-pro"
    })

    # Check Hugging Face
    try:
        _, _, pipe = initialize_huggingface()
        models.append({
            "name": "huggingface",
            "available": pipe is not None,
            "type": "local" if not HUGGINGFACE_API_KEY else "api",
            "model": HUGGINGFACE_MODEL_ID
        })
    except Exception:
        models.append({
            "name": "huggingface",
            "available": False,
            "type": "local",
            "error": "Failed to initialize"
        })

    return models


if __name__ == "__main__":
    # Simple test for the module
    models = get_available_models()
    print(json.dumps(models, indent=2))

    # Test a model if available
    for model_info in models:
        if model_info["available"]:
            model_name = model_info["name"]
            print(f"\nTesting {model_name} model...")

            test_log = "2023-05-01 12:34:56 ERROR Failed to connect to database: Connection refused"
            result = analyze_log(test_log, model_name)

            print(f"\nAnalysis result from {model_name}:")
            print(result)
            break (duplicate-code)
server/backend/ai_model.py:1:0: R0801: Similar lines in 2 files
==client.adjust_hierarchy_with_debugger:[52:70]
==patch.ailinux-alpha-patch-v0.3:[172:583]
    try:
        result = subprocess.run(
            ['pylint', '--disable=all', '--enable=error'],
            capture_output=True,
            text=True,
            check=True
        )
        print(result.stdout)
        if result.stderr:
            print("Error:", result.stderr)
    except FileNotFoundError:
        print("Pylint is not installed. Install it with 'pip install pylint'.")


if __name__ == "__main__":
    base_dir = '/home/zombie/ailinux'
    restore_directory_structure(base_dir)
    run_pylint() (duplicate-code)
server/backend/ai_model.py:1:0: R0801: Similar lines in 2 files
==client.adjust_hierarchy_with_debugger:[32:52]
==patch.ailinux-alpha-patch-v0.3:[152:170]
        for key, value in structure.items():
            target_dir = os.path.join(target_path, key)
            if isinstance(value, list):
                os.makedirs(target_dir, exist_ok=True)
                for file in value:
                    file_path = os.path.join(target_dir, file)
                    if not os.path.exists(file_path):
                        with open(file_path, 'w', encoding='utf-8') as f:
                            f.write('')
            elif isinstance(value, dict):
                os.makedirs(target_dir, exist_ok=True)
                create_structure(target_dir, value)

    # Create the directory structure
    create_structure(base_dir, expected_structure)
    print(f"Directory structure verified and restored in {base_dir}")

 (duplicate-code)
server/backend/ai_model.py:1:0: R0801: Similar lines in 2 files
==client.adjust_hierarchy_with_debugger:[18:32]
==patch.ailinux-alpha-patch-v0.3:[138:150]
    expected_structure = {
        'backend': {
            'backend': ['ai_model.py', 'app.py', 'backend.js', 'package-lock.json'],
            'frontend': ['config.py', 'index.html', 'main.js', 'package.json'],
            'models': [],
            'lib': ['libggml-base.so', 'libggml-cpu-alderlake.so'],
        },
        'logs': ['backend.log', 'frontend.log'],
        'readme': ['README.md']
    }

    # Helper function to create the directory structure
    def create_structure(target_path, structure):
        """Create directories and files based on expected structure.""" (duplicate-code)
server/backend/ai_model.py:1:0: R0801: Similar lines in 2 files
==client.adjust_hierarchy_with_debugger:[52:61]
==patch.ailinux-alpha-patch-v0.3:[33:42]
    try:
        result = subprocess.run(
            ['pylint', '--disable=all', '--enable=error'],
            capture_output=True,
            text=True,
            check=True
        )
        print(result.stdout)
        if result.stderr: (duplicate-code)

------------------------------------------------------------------
Your code has been rated at 0.00/10 (previous run: 5.96/10, -5.96)

